{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Prisoner's Dilemma\n",
    "\n",
    "\n",
    "### Description\n",
    "\n",
    "The [Prisoner's Dilemma](https://en.wikipedia.org/wiki/Prisoner%27s_dilemma) (PD) is a classical game analyzed in game theory, which is widely used to (attempt to) model social/economical interaction. It's a \"dilemma\" as, if exploited to explain the emergence of altruism in human or in general animal society, it fails badly at a first glance.\n",
    "\n",
    "The classical situation-representation of the PD is that of two prisoners whose conviction depends on their mutual cooperation. It is easier understood though if illustrated in terms of a trade-off game (closed bag exachange):\n",
    "\n",
    "*Two people meet and exchange closed bags, with the understanding that one of them contains money, and the other contains a purchase. Either player can choose to honor the deal by putting into his or her bag what he or she agreed, or he or she can defect by handing over an empty bag.*\n",
    "\n",
    "It is obvious that for both players the winning strategy is to NOT cooperate.\n",
    "\n",
    "Things changes when the interaction between the two individuals is iterated, in that case a more altruist attitude (strategy) is expected to emerge. The goal of this project is to test this hypothesis.\n",
    "\n",
    "Mathematically the PD can be expressed with very basic linear algebra. The key component is the **Payoff matrix** $M$, which quantify the reward each player gets depending on whether she cooperated or not (defect):\n",
    "\n",
    "$$\n",
    "M = \n",
    "\\begin{pmatrix} \n",
    "R & S \\\\\n",
    "T & P \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "* $R$ : reward, $P$ : punishment, $T$ : temptation, $S$ : sucker\n",
    "\n",
    "with $T,R,S,P$ integers that satisfy the following conditions:\n",
    "\n",
    "$$\n",
    "T>R>P>S; \\quad 2R > T+S\n",
    "$$\n",
    "\n",
    "for example $T=3$, $R=2$, $P=1$ and $S=0$, or  $T=5$, $R=3$, $P=2$, $S=0$. Each player choice (move) can be represented by one of the two axis in ${\\rm I\\!R}^2$, i.e. $u_C=\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ or $u_D=\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, where the first coordinate stands for *Cooperate* and the second for *Defect*. Being $u_1$ and $u_2$ their rewards $r_1$ and $r_2$ can be computed then as:\n",
    "\n",
    "$$\n",
    "r_1 = u_1^T M u_2\n",
    "\\quad\n",
    "\\quad\n",
    "r_2 = u_2^T M u_1\n",
    "$$\n",
    "\n",
    "In an Iterative Prisoner's Dilemma (IPD), two players play prisoner's dilemma more than once in succession and they remember previous actions of their opponent and change their strategy accordingly. The winning strategy is the one which yields to a larger reward at the end of the IPD.\n",
    "\n",
    "The strategy can be represented as a function which outputs either $u_C$ or $u_D$. Such function can depend on the opponent's history of moves, her on history of moves, on the number of moves played till that moment and so on, but it can only be based on a probability density function. Possible strategies are:\n",
    "\n",
    "* **Nice guy**: always cooperate (the function's output is always $u_D$)\n",
    "* **Bad guy**: always defect \n",
    "* **Mainly nice**: randomly defect $k\\%$ of the times and cooperate $100-k\\%$, $k<50$\n",
    "* **Mainly bad**: randomly defect $k\\%$ of the times and cooperate $100-k\\%$, $k>50$\n",
    "* **tit-for-tat**: start by cooperating, then repeat what the opponent has done in the previous move \n",
    "\n",
    "Many more and much more complex strategies can be implemented. The strategy can even change during the IPD.\n",
    "\n",
    "\n",
    "### Assignments\n",
    "\n",
    "* Implement a simple IPD between two players implementing two given strategies. Study the evolution along the tournament confronting different strategies; study the overall outcome in the different configurations. \n",
    "* Implement a multiple players IPD (MPIPD) where several strategies play against each other in a roud-robin scheme\n",
    "* Iterate what done in the previous task (repeated MPIPD, rMPIPD)  by increasing the population implementing a given strategy depending on the results that strategy achieved in the previous iteration\n",
    "* (*difficult*) Implement a rMPIPD where strategies are allowed to mutate. The goal is to simulate the effect of genetic mutations and the effect of natura selection. A parameter (gene) should encode the attidue of an individual to cooperate, such gene can mutate randomly and the corresponding phenotype should compete in the MPIPD such that the best-fitted is determined.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions of the Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import all necessary modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions and classes\n",
    "\n",
    "In this section we define the core classes and functionallities needed to solve the given assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Auxiliary functions -----\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "\n",
    "# Main class for the players\n",
    "class Player():\n",
    "    def __init__(self, strategy, initial_action, name):\n",
    "        '''\n",
    "        Params:\n",
    "            strategy : dict\n",
    "                Dictionary with two keys which represent\n",
    "                the previous action of the opponent. 0 for\n",
    "                cooperation and 1 for defection. \n",
    "                The corresponding entries are a number \n",
    "                between 0 and 1, representing the probability\n",
    "                that the player cooperates given the previous\n",
    "                move of the opponent.\n",
    "    \n",
    "            initial_action : float\n",
    "                A number between 0 and 1, representing the \n",
    "                probability that the player cooperates in\n",
    "                the first turn.\n",
    "                \n",
    "            name : str\n",
    "                Name of the player.\n",
    "        '''\n",
    "        self.strategy = strategy\n",
    "        self.initial_action = initial_action\n",
    "        self.name = name\n",
    "        \n",
    "    def GetInitialAction(self, r):\n",
    "        '''\n",
    "        Params:\n",
    "            r : float\n",
    "                Randomly drawn number from 0 to 1.\n",
    "        \n",
    "        Ouput:\n",
    "            Returns a 0 if r <= self.initial_action \n",
    "            and 1 otherwise.\n",
    "        '''\n",
    "        return 1 - int(r <= self.initial_action)\n",
    "        \n",
    "        \n",
    "    def GetNextAction(self, prev_opponent_action, r):\n",
    "        '''\n",
    "        Params:\n",
    "            prev_opponent_action : int\n",
    "                Either a 0 (cooperation) or a 1 (defection)\n",
    "                corresponding to the previous action of the\n",
    "                player.\n",
    "                \n",
    "            r : float\n",
    "                Randomly drawn number from 0 to 1.\n",
    "        \n",
    "        Ouput:\n",
    "            Returns a 0 if r <= P(action) and 1 otherwise,\n",
    "            where P(action) is the probability of cooperating\n",
    "            given the previous action of the oponent.\n",
    "        '''\n",
    "        action_prob = self.strategy[prev_opponent_action]\n",
    "        next_move = int(r <= action_prob)\n",
    "        return next_move\n",
    "    \n",
    "    \n",
    "# Main class for a single game\n",
    "class Game():\n",
    "    def __init__(self, M, player_1, player_2, N, seed=42):\n",
    "        '''\n",
    "        Params:\n",
    "            M : numpy array\n",
    "                Array of shape (2, 2) containing the\n",
    "                payoff matrix, which is used to \n",
    "                calculate the reward each player \n",
    "                receives after a single iteration.\n",
    "                \n",
    "            player_1, player_2 : Player\n",
    "                The two Player instances that will\n",
    "                participate in the game.\n",
    "                \n",
    "            N : int\n",
    "                Number of iterations of the game.\n",
    "                \n",
    "            seed : int (optional)\n",
    "                Seed for the random number generator. \n",
    "                Default value is 42.\n",
    "        '''\n",
    "        self.M = M \n",
    "        self.player_1 = player_1\n",
    "        self.player_2 = player_2\n",
    "        self.N = N\n",
    "        \n",
    "        # Some additional attributes:\n",
    "        # Action history for both players\n",
    "        self.history_1 = []\n",
    "        self.history_2 = []\n",
    "        # Reward history for both players\n",
    "        self.rewards_1 = []\n",
    "        self.rewards_2 = []\n",
    "        \n",
    "        # Initialize random seed\n",
    "        np.random.seed(seed)\n",
    "       \n",
    "    \n",
    "    def GetReward(self, action_1, action_2):\n",
    "        '''\n",
    "        Params:\n",
    "            action_1, action_2 : int\n",
    "                Actions from players 1 and 2, respectively, \n",
    "                where 0 corresponds to cooperation and 1 to\n",
    "                defection.\n",
    "        \n",
    "        Output:\n",
    "            Returns a tuple of two values containing the\n",
    "            reward estimated for players 1 and 2, respectively.\n",
    "        '''\n",
    "        reward_1 = self.M[action_1, action_2]\n",
    "        reward_2 = self.M[action_2, action_1]\n",
    "        return reward_1, reward_2\n",
    "    \n",
    "    \n",
    "    def SaveHistory(self, action_1, action_2, reward_1, reward_2):\n",
    "        '''\n",
    "        Params:\n",
    "            action_1, action_2 : int\n",
    "                Latest action of players 1 and 2 respectively.\n",
    "            \n",
    "            reward_1, reward_2 : int\n",
    "                Latest reward of players 1 and 2 respectively.\n",
    "                \n",
    "        Output:\n",
    "            Saves the latest actions and rewards to their \n",
    "            corresponding history.\n",
    "        '''\n",
    "        # Save actions\n",
    "        self.history_1.append(action_1)\n",
    "        self.history_2.append(action_2)\n",
    "        \n",
    "        # Save rewards\n",
    "        self.rewards_1.append(reward_1)\n",
    "        self.rewards_2.append(reward_2)\n",
    "        \n",
    "        \n",
    "    def InitialIteration(self, r_1, r_2):\n",
    "        '''\n",
    "        Params:\n",
    "            r_1, r_2 : float\n",
    "                Randomly drawn numbers from 0 to 1.\n",
    "            \n",
    "        Output:\n",
    "            Performs the initial iteration of the game.\n",
    "        '''\n",
    "        # Get initial actions \n",
    "        action_1 = self.player_1.GetInitialAction(r_1)\n",
    "        action_2 = self.player_2.GetInitialAction(r_2)\n",
    "        \n",
    "        # Get initial rewards\n",
    "        reward_1, reward_2 = self.GetReward(action_1, action_2)\n",
    "        \n",
    "        # Save actions and rewards\n",
    "        self.SaveHistory(action_1, action_2, reward_1, reward_2)\n",
    "    \n",
    "    \n",
    "    def SingleIteration(self, r_1, r_2):\n",
    "        '''\n",
    "        Params:\n",
    "            r_1, r_2 : float\n",
    "                Randomly drawn numbers from 0 to 1.\n",
    "            \n",
    "        Output:\n",
    "            Performs a new iteration of the game. This\n",
    "            method must be called after the initial\n",
    "            iteration of the game.\n",
    "        '''\n",
    "        # Get previous action from both players\n",
    "        prev_1 = self.history_1[-1]\n",
    "        prev_2 = self.history_2[-1]\n",
    "        \n",
    "        # Get new actions\n",
    "        action_1 = self.player_1.GetNextAction(prev_2, r_1)\n",
    "        action_2 = self.player_2.GetNextAction(prev_1, r_2)\n",
    "        \n",
    "        # Get rewards\n",
    "        reward_1, reward_2 = self.GetReward(action_1, action_2)\n",
    "        \n",
    "        # Save actions and rewards\n",
    "        self.SaveHistory(action_1, action_2, reward_1, reward_2)\n",
    "        \n",
    "    \n",
    "    def Play(self):\n",
    "        '''\n",
    "        Plays the entire game.\n",
    "        \n",
    "        Output:\n",
    "            Returns a dictionary with the results of the game,\n",
    "            with the following keys:\n",
    "             - 'actions_player_1'\n",
    "             - 'rewards_player_1'\n",
    "             - 'actions_player_2'\n",
    "             - 'rewards_player_2'\n",
    "        '''\n",
    "        # Generate random numbers for both players\n",
    "        r_1 = np.random.uniform(size=self.N)\n",
    "        r_2 = np.random.uniform(size=self.N)\n",
    "        \n",
    "        # Perform initial iteration\n",
    "        self.InitialIteration(r_1[0], r_2[0])\n",
    "        \n",
    "        # Perform remaining iterations\n",
    "        for i in range(self.N - 1):\n",
    "            self.SingleIteration(r_1[i+1], r_2[i+1])\n",
    "        \n",
    "        # Build and return final dictionary\n",
    "        final_dict = {'actions_' + self.player_1.name: self.history_1.copy(),\n",
    "                      'rewards_' + self.player_1.name: self.rewards_1.copy(),\n",
    "                      'actions_' + self.player_2.name: self.history_2.copy(),\n",
    "                      'rewards_' + self.player_2.name: self.rewards_2.copy()}\n",
    "        return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
